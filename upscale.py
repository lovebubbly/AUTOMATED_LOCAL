"""
Video Upscaler - Real-ESRGAN based video upscaling module

720p â†’ 1440p ë¹„ë””ì˜¤ ì—…ìŠ¤ì¼€ì¼ì„ ìœ„í•œ ëª¨ë“ˆì…ë‹ˆë‹¤.
Real-ESRGANì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ë³„ë¡œ ì—…ìŠ¤ì¼€ì¼ í›„ ì¬ì¡°í•©í•©ë‹ˆë‹¤.
"""

import os
import subprocess
import shutil
import tempfile
from pathlib import Path
from typing import Optional, Callable
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class VideoUpscaler:
    """
    Real-ESRGAN ê¸°ë°˜ ë¹„ë””ì˜¤ ì—…ìŠ¤ì¼€ì¼ëŸ¬.
    
    720p (1280x720) â†’ 1440p (2560x1440) ì—…ìŠ¤ì¼€ì¼ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        model_name: str = "realesr-animevideov3",
        scale: int = 2,
        gpu_id: int = 0
    ):
        """
        Args:
            model_name: Real-ESRGAN ëª¨ë¸ëª…
                - "realesr-animevideov3" (ì• ë‹ˆë©”ì´ì…˜/AI ìƒì„± ì˜ìƒì— ìµœì )
                - "RealESRGAN_x4plus" (ì‹¤ì‚¬ ì˜ìƒ)
                - "RealESRGAN_x4plus_anime_6B" (ì• ë‹ˆë©”ì´ì…˜)
            scale: ì—…ìŠ¤ì¼€ì¼ ë°°ìœ¨ (2 = 720pâ†’1440p, 4 = 720pâ†’4K)
            gpu_id: ì‚¬ìš©í•  GPU ID
        """
        self.model_name = model_name
        self.scale = scale
        self.gpu_id = gpu_id
        self._check_dependencies()
    
    def _check_dependencies(self) -> None:
        """í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸."""
        # Check for realesrgan-ncnn-vulkan or Python realesrgan
        self.use_ncnn = shutil.which("realesrgan-ncnn-vulkan") is not None
        
        if not self.use_ncnn:
            try:
                from realesrgan import RealESRGANer
                self.use_python = True
            except ImportError:
                self.use_python = False
                logger.warning(
                    "Real-ESRGAN not found. Install via:\n"
                    "  pip install realesrgan basicsr\n"
                    "Or download realesrgan-ncnn-vulkan from:\n"
                    "  https://github.com/xinntao/Real-ESRGAN-ncnn-vulkan/releases"
                )
        else:
            self.use_python = False
    
    def upscale_video(
        self,
        input_path: str,
        output_path: Optional[str] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> str:
        """
        ë¹„ë””ì˜¤ë¥¼ ì—…ìŠ¤ì¼€ì¼í•©ë‹ˆë‹¤.
        
        Args:
            input_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
            progress_callback: ì§„í–‰ë¥  ì½œë°± (current_frame, total_frames)
            
        Returns:
            ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        """
        input_path = Path(input_path)
        if not input_path.exists():
            raise FileNotFoundError(f"Input video not found: {input_path}")
        
        if output_path is None:
            stem = input_path.stem
            suffix = input_path.suffix
            output_path = input_path.parent / f"{stem}_1440p{suffix}"
        else:
            output_path = Path(output_path)
        
        logger.info(f"ğŸ¬ Upscaling video: {input_path}")
        logger.info(f"   Output: {output_path}")
        logger.info(f"   Scale: {self.scale}x, Model: {self.model_name}")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            frames_dir = Path(temp_dir) / "frames"
            upscaled_dir = Path(temp_dir) / "upscaled"
            frames_dir.mkdir()
            upscaled_dir.mkdir()
            
            # Step 1: Extract frames
            logger.info("ğŸ“¤ Extracting frames...")
            fps = self._extract_frames(input_path, frames_dir)
            
            # Step 2: Upscale frames
            logger.info("ğŸ”„ Upscaling frames...")
            frame_count = len(list(frames_dir.glob("*.png")))
            self._upscale_frames(frames_dir, upscaled_dir, progress_callback, frame_count)
            
            # Step 3: Reassemble video
            logger.info("ğŸ“¥ Reassembling video...")
            self._reassemble_video(upscaled_dir, output_path, fps, input_path)
        
        logger.info(f"âœ… Upscaling complete: {output_path}")
        return str(output_path)
    
    def _extract_frames(self, video_path: Path, output_dir: Path) -> float:
        """FFmpegë¡œ í”„ë ˆì„ ì¶”ì¶œ."""
        # Get video FPS
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-select_streams", "v:0",
            "-show_entries", "stream=r_frame_rate",
            "-of", "csv=p=0",
            str(video_path)
        ]
        result = subprocess.run(probe_cmd, capture_output=True, text=True)
        fps_str = result.stdout.strip()
        if "/" in fps_str:
            num, den = map(int, fps_str.split("/"))
            fps = num / den
        else:
            fps = float(fps_str) if fps_str else 30.0
        
        # Extract frames
        extract_cmd = [
            "ffmpeg", "-i", str(video_path),
            "-qscale:v", "2",
            str(output_dir / "frame_%06d.png")
        ]
        subprocess.run(extract_cmd, capture_output=True, check=True)
        
        return fps
    
    def _upscale_frames(
        self,
        input_dir: Path,
        output_dir: Path,
        progress_callback: Optional[Callable],
        total_frames: int
    ) -> None:
        """í”„ë ˆì„ ì—…ìŠ¤ì¼€ì¼."""
        if self.use_ncnn:
            # Use realesrgan-ncnn-vulkan
            cmd = [
                "realesrgan-ncnn-vulkan",
                "-i", str(input_dir),
                "-o", str(output_dir),
                "-n", self.model_name,
                "-s", str(self.scale),
                "-g", str(self.gpu_id),
                "-f", "png"
            ]
            subprocess.run(cmd, check=True)
        elif self.use_python:
            self._upscale_frames_python(input_dir, output_dir, progress_callback, total_frames)
        else:
            raise RuntimeError("No Real-ESRGAN backend available")
    
    def _upscale_frames_python(
        self,
        input_dir: Path,
        output_dir: Path,
        progress_callback: Optional[Callable],
        total_frames: int
    ) -> None:
        """Python Real-ESRGANìœ¼ë¡œ í”„ë ˆì„ ì—…ìŠ¤ì¼€ì¼."""
        import cv2
        import torch
        from basicsr.archs.rrdbnet_arch import RRDBNet
        from realesrgan import RealESRGANer
        from realesrgan.archs.srvgg_arch import SRVGGNetCompact
        
        # Initialize model - architecture must match the pretrained weights
        if self.model_name == "realesr-animevideov3":
            # realesr-animevideov3 uses SRVGGNetCompact (VGG-style, NOT RRDBNet!)
            model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=16, upscale=4, act_type='prelu')
            netscale = 4
            model_url = "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-animevideov3.pth"
        elif self.model_name == "realesrgan-x4plus-anime":
            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=6, num_grow_ch=32, scale=4)
            netscale = 4
            model_url = "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth"
        else:
            # Default: RealESRGAN_x4plus (23 blocks)
            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)
            netscale = 4
            model_url = "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth"
        
        logger.info(f"   Loading model: {self.model_name} (native scale: {netscale}x)")
        
        upsampler = RealESRGANer(
            scale=netscale,
            model_path=model_url,  # Auto-download from URL
            model=model,
            half=True,
            gpu_id=self.gpu_id
        )
        
        frames = sorted(input_dir.glob("*.png"))
        for i, frame_path in enumerate(frames):
            img = cv2.imread(str(frame_path), cv2.IMREAD_UNCHANGED)
            output, _ = upsampler.enhance(img, outscale=self.scale)
            
            output_path = output_dir / frame_path.name
            cv2.imwrite(str(output_path), output)
            
            if progress_callback:
                progress_callback(i + 1, total_frames)
    
    def _reassemble_video(
        self,
        frames_dir: Path,
        output_path: Path,
        fps: float,
        original_video: Path
    ) -> None:
        """FFmpegë¡œ ë¹„ë””ì˜¤ ì¬ì¡°í•©."""
        # Check if original has audio
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-select_streams", "a:0",
            "-show_entries", "stream=codec_type",
            "-of", "csv=p=0",
            str(original_video)
        ]
        result = subprocess.run(probe_cmd, capture_output=True, text=True)
        has_audio = "audio" in result.stdout
        
        if has_audio:
            # With audio
            cmd = [
                "ffmpeg", "-y",
                "-framerate", str(fps),
                "-i", str(frames_dir / "frame_%06d.png"),
                "-i", str(original_video),
                "-map", "0:v", "-map", "1:a?",
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                "-pix_fmt", "yuv420p",
                "-c:a", "aac",
                str(output_path)
            ]
        else:
            # No audio
            cmd = [
                "ffmpeg", "-y",
                "-framerate", str(fps),
                "-i", str(frames_dir / "frame_%06d.png"),
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                "-pix_fmt", "yuv420p",
                str(output_path)
            ]
        
        subprocess.run(cmd, capture_output=True, check=True)


def upscale_video(
    input_path: str,
    output_path: Optional[str] = None,
    scale: int = 2,
    model: str = "realesr-animevideov3"
) -> str:
    """
    ë¹„ë””ì˜¤ ì—…ìŠ¤ì¼€ì¼ ê°„í¸ í•¨ìˆ˜.
    
    Args:
        input_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        scale: ì—…ìŠ¤ì¼€ì¼ ë°°ìœ¨ (2 = 720pâ†’1440p)
        model: Real-ESRGAN ëª¨ë¸ëª…
        
    Returns:
        ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
    """
    upscaler = VideoUpscaler(model_name=model, scale=scale)
    return upscaler.upscale_video(input_path, output_path)


# CLI support
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python upscale.py <input_video> [output_video]")
        print("       Upscales 720p video to 1440p using Real-ESRGAN")
        sys.exit(1)
    
    input_video = sys.argv[1]
    output_video = sys.argv[2] if len(sys.argv) > 2 else None
    
    try:
        result = upscale_video(input_video, output_video)
        print(f"âœ… Output saved to: {result}")
    except Exception as e:
        print(f"âŒ Error: {e}")
        sys.exit(1)


# ============================================================
# VIDEO CONCATENATION
# ============================================================

class VideoConcatenator:
    """
    ì—¬ëŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ì„ í•˜ë‚˜ë¡œ ì´ì–´ë¶™ì´ëŠ” í´ë˜ìŠ¤.
    
    FFmpegì˜ concat demuxerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬´ì†ì‹¤ ì—°ê²°í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, output_dir: Optional[str] = None):
        """
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ì²« ë²ˆì§¸ ì…ë ¥ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
        """
        self.output_dir = Path(output_dir) if output_dir else None
    
    def concatenate(
        self,
        video_paths: list,
        output_filename: str = "final_output.mp4",
        reencode: bool = False
    ) -> str:
        """
        ì—¬ëŸ¬ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
        
        Args:
            video_paths: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ìˆœì„œëŒ€ë¡œ ì—°ê²°)
            output_filename: ì¶œë ¥ íŒŒì¼ëª…
            reencode: Trueë©´ ì¬ì¸ì½”ë”© (ë‹¤ë¥¸ ì½”ë±/í•´ìƒë„ ë¹„ë””ì˜¤ ì—°ê²° ì‹œ)
            
        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        if len(video_paths) < 2:
            raise ValueError("At least 2 videos required for concatenation")
        
        # Validate all files exist
        video_paths = [Path(p) for p in video_paths]
        for vp in video_paths:
            if not vp.exists():
                raise FileNotFoundError(f"Video not found: {vp}")
        
        # Determine output directory
        if self.output_dir:
            output_dir = self.output_dir
        else:
            output_dir = video_paths[0].parent
        
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / output_filename
        
        logger.info(f"ğŸ¬ Concatenating {len(video_paths)} videos...")
        
        if reencode:
            self._concat_with_reencode(video_paths, output_path)
        else:
            self._concat_demuxer(video_paths, output_path)
        
        logger.info(f"âœ… Concatenation complete: {output_path}")
        return str(output_path)
    
    def _concat_demuxer(self, video_paths: list, output_path: Path) -> None:
        """FFmpeg concat demuxer ì‚¬ìš© (ë¬´ì†ì‹¤, ê°™ì€ ì½”ë± í•„ìš”)."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            for vp in video_paths:
                # Escape single quotes in path
                escaped_path = str(vp.absolute()).replace("'", "'\\''")
                f.write(f"file '{escaped_path}'\n")
            concat_list = f.name
        
        try:
            cmd = [
                "ffmpeg", "-y",
                "-f", "concat",
                "-safe", "0",
                "-i", concat_list,
                "-c", "copy",
                str(output_path)
            ]
            subprocess.run(cmd, capture_output=True, check=True)
        finally:
            os.unlink(concat_list)
    
    def _concat_with_reencode(self, video_paths: list, output_path: Path) -> None:
        """ì¬ì¸ì½”ë”©í•˜ë©´ì„œ ì—°ê²° (ë‹¤ë¥¸ ì½”ë±/í•´ìƒë„ ì§€ì›)."""
        # Check if videos have audio
        has_audio = self._check_video_has_audio(video_paths[0])
        
        # Build filter complex for concat
        filter_complex = ""
        for i in range(len(video_paths)):
            if has_audio:
                filter_complex += f"[{i}:v][{i}:a]"
            else:
                filter_complex += f"[{i}:v]"
        
        if has_audio:
            filter_complex += f"concat=n={len(video_paths)}:v=1:a=1[outv][outa]"
        else:
            filter_complex += f"concat=n={len(video_paths)}:v=1:a=0[outv]"
        
        cmd = [
            "ffmpeg", "-y",
        ]
        for vp in video_paths:
            cmd.extend(["-i", str(vp)])
        
        if has_audio:
            cmd.extend([
                "-filter_complex", filter_complex,
                "-map", "[outv]",
                "-map", "[outa]",
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                "-c:a", "aac",
                "-b:a", "192k",
                str(output_path)
            ])
        else:
            cmd.extend([
                "-filter_complex", filter_complex,
                "-map", "[outv]",
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                str(output_path)
            ])
        subprocess.run(cmd, capture_output=True, check=True)
    
    def _check_video_has_audio(self, video_path: Path) -> bool:
        """ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì´ ìˆëŠ”ì§€ í™•ì¸."""
        try:
            probe_cmd = [
                "ffprobe", "-v", "error",
                "-select_streams", "a:0",
                "-show_entries", "stream=codec_type",
                "-of", "csv=p=0",
                str(video_path)
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True)
            return "audio" in result.stdout
        except Exception:
            return False
    
    def concatenate_directory(
        self,
        directory: str,
        pattern: str = "*.mp4",
        output_filename: str = "final_output.mp4",
        sort_by: str = "name"
    ) -> str:
        """
        ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
        
        Args:
            directory: ë¹„ë””ì˜¤ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬
            pattern: íŒŒì¼ íŒ¨í„´ (ì˜ˆ: "*.mp4", "block_*.mp4")
            output_filename: ì¶œë ¥ íŒŒì¼ëª…
            sort_by: ì •ë ¬ ê¸°ì¤€ ("name" ë˜ëŠ” "time")
            
        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        dir_path = Path(directory)
        if not dir_path.exists():
            raise FileNotFoundError(f"Directory not found: {directory}")
        
        videos = list(dir_path.glob(pattern))
        if not videos:
            raise ValueError(f"No videos matching '{pattern}' in {directory}")
        
        # Sort videos
        if sort_by == "name":
            videos.sort(key=lambda x: x.name)
        elif sort_by == "time":
            videos.sort(key=lambda x: x.stat().st_mtime)
        else:
            raise ValueError(f"Invalid sort_by: {sort_by}")
        
        logger.info(f"ğŸ“‚ Found {len(videos)} videos in {directory}")
        for i, v in enumerate(videos):
            logger.info(f"   {i+1}. {v.name}")
        
        return self.concatenate(videos, output_filename)


def concat_videos(
    video_paths: list,
    output_path: Optional[str] = None,
    reencode: bool = False
) -> str:
    """
    ë¹„ë””ì˜¤ ì—°ê²° ê°„í¸ í•¨ìˆ˜.
    
    Args:
        video_paths: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        reencode: ì¬ì¸ì½”ë”© ì—¬ë¶€
        
    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    output_filename = Path(output_path).name if output_path else "final_output.mp4"
    output_dir = Path(output_path).parent if output_path else None
    
    concat = VideoConcatenator(output_dir=str(output_dir) if output_dir else None)
    return concat.concatenate(video_paths, output_filename, reencode)


def concat_directory(
    directory: str,
    pattern: str = "*.mp4",
    output_filename: str = "final_output.mp4"
) -> str:
    """
    ë””ë ‰í† ë¦¬ ë‚´ ë¹„ë””ì˜¤ ì—°ê²° ê°„í¸ í•¨ìˆ˜.
    
    Args:
        directory: ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬
        pattern: íŒŒì¼ íŒ¨í„´
        output_filename: ì¶œë ¥ íŒŒì¼ëª…
        
    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    concat = VideoConcatenator()
    return concat.concatenate_directory(directory, pattern, output_filename)


# ============================================================
# SMART CONCATENATOR - Scene-aware transitions
# ============================================================

class SmartConcatenator:
    """
    ìŠ¤ë§ˆíŠ¸ ë¹„ë””ì˜¤ ì—°ê²°ê¸° - CSV ë¶„ì„í•˜ì—¬ ìƒˆ ì”¬ì—ë§Œ íŠ¸ëœì§€ì…˜ ì ìš©.
    
    Production Table CSVë¥¼ ë¶„ì„í•˜ì—¬:
    - [Input: Last Frame]ë¡œ ì‹œì‘í•˜ëŠ” ë¸”ë¡: íŠ¸ëœì§€ì…˜ ì—†ì´ ì—°ê²° (ì—°ì† ì”¬)
    - ìƒˆ í”„ë¡¬í”„íŠ¸ë¡œ ì‹œì‘í•˜ëŠ” ë¸”ë¡: í¬ë¡œìŠ¤í˜ì´ë“œ íŠ¸ëœì§€ì…˜ ì ìš© (ìƒˆ ì”¬)
    """
    
    def __init__(
        self,
        csv_path: str,
        video_dir: str,
        transition_duration: float = 0.3,
        transition_type: str = "crossfade"
    ):
        """
        Args:
            csv_path: Production Table CSV ê²½ë¡œ
            video_dir: ë¹„ë””ì˜¤ íŒŒì¼ ë””ë ‰í† ë¦¬
            transition_duration: íŠ¸ëœì§€ì…˜ ê¸¸ì´ (ì´ˆ)
            transition_type: íŠ¸ëœì§€ì…˜ íƒ€ì… ("crossfade", "fade_black")
        """
        self.csv_path = Path(csv_path)
        self.video_dir = Path(video_dir)
        self.transition_duration = transition_duration
        self.transition_type = transition_type
        
        if not self.csv_path.exists():
            raise FileNotFoundError(f"CSV not found: {csv_path}")
        if not self.video_dir.exists():
            raise FileNotFoundError(f"Video directory not found: {video_dir}")
    
    def analyze_transitions(self) -> list:
        """
        CSVë¥¼ ë¶„ì„í•˜ì—¬ íŠ¸ëœì§€ì…˜ì´ í•„ìš”í•œ ë¸”ë¡ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Returns:
            list of tuples: [(block_id, needs_transition), ...]
        """
        import pandas as pd
        
        df = pd.read_csv(self.csv_path)
        transitions = []
        
        for index, row in df.iterrows():
            block_id = str(row['Block']).zfill(2)
            start_frame_prompt = str(row.get('Nano Banana (Start Frame)', ''))
            section = str(row.get('Section', ''))
            
            # ì´ì „ ë¸”ë¡ì˜ ì„¹ì…˜ (ìˆë‹¤ë©´)
            prev_section = df.iloc[index - 1]['Section'] if index > 0 else None
            
            # íŠ¸ëœì§€ì…˜ì´ í•„ìš”í•œ ì¡°ê±´:
            # 1. [Input: Last Frame]ë¡œ ì‹œì‘í•˜ì§€ ì•ŠìŒ (ìƒˆ ì”¬)
            # 2. ì„¹ì…˜ì´ ë³€ê²½ë¨ (Intro â†’ Verse ë“±)
            # 3. ì²« ë¸”ë¡ì´ ì•„ë‹˜
            is_continuation = "[Input: Last Frame" in start_frame_prompt or "[Loop Bank" in start_frame_prompt
            section_changed = prev_section is not None and section != prev_section
            
            needs_transition = False
            if index > 0:  # ì²« ë¸”ë¡ì€ íŠ¸ëœì§€ì…˜ ë¶ˆí•„ìš”
                if not is_continuation or section_changed:
                    needs_transition = True
            
            transitions.append({
                'block_id': block_id,
                'needs_transition': needs_transition,
                'section': section,
                'reason': 'new_scene' if not is_continuation else ('section_change' if section_changed else 'continuation')
            })
            
            logger.debug(f"Block {block_id}: transition={needs_transition}, reason={transitions[-1]['reason']}")
        
        return transitions
    
    def concatenate_smart(
        self,
        output_filename: str = "final_smart.mp4",
        video_pattern: str = "block_{block_id}_video.mp4"
    ) -> str:
        """
        ìŠ¤ë§ˆíŠ¸ íŠ¸ëœì§€ì…˜ìœ¼ë¡œ ë¹„ë””ì˜¤ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
        
        Args:
            output_filename: ì¶œë ¥ íŒŒì¼ëª…
            video_pattern: ë¹„ë””ì˜¤ íŒŒì¼ íŒ¨í„´ ({block_id}ëŠ” ìë™ ì¹˜í™˜)
            
        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        transitions = self.analyze_transitions()
        
        # ì¡´ì¬í•˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        video_segments = []
        for t in transitions:
            video_name = video_pattern.format(block_id=t['block_id'])
            video_path = self.video_dir / video_name
            if video_path.exists():
                video_segments.append({
                    'path': video_path,
                    'block_id': t['block_id'],
                    'needs_transition': t['needs_transition'],
                    'reason': t['reason']
                })
            else:
                logger.warning(f"Video not found: {video_path}")
        
        if not video_segments:
            raise ValueError("No video files found")
        
        logger.info(f"ğŸ¬ Smart concatenation: {len(video_segments)} videos")
        for seg in video_segments:
            trans_mark = "ğŸ”€" if seg['needs_transition'] else "â¡ï¸"
            logger.info(f"   {trans_mark} Block {seg['block_id']} ({seg['reason']})")
        
        # íŠ¸ëœì§€ì…˜ í•„ìš”í•œ ë¶€ë¶„ ì¹´ìš´íŠ¸
        trans_count = sum(1 for seg in video_segments if seg['needs_transition'])
        logger.info(f"ğŸ“Š {trans_count} transitions will be applied")
        
        # FFmpegë¡œ ìŠ¤ë§ˆíŠ¸ ì—°ê²°
        output_path = self.video_dir / output_filename
        self._concatenate_with_transitions(video_segments, output_path)
        
        logger.info(f"âœ… Smart output saved: {output_path}")
        return str(output_path)
    
    def _concatenate_with_transitions(self, segments: list, output_path: Path) -> None:
        """
        FFmpegë¡œ íŠ¸ëœì§€ì…˜ í¬í•¨ ì—°ê²° (2ë‹¨ê³„ ë°©ì‹).
        
        1ë‹¨ê³„: ì—°ì† ì”¬(needs_transition=False)ë¼ë¦¬ ê·¸ë£¹ìœ¼ë¡œ concat
        2ë‹¨ê³„: ê·¸ë£¹ ì‚¬ì´ì— xfade íŠ¸ëœì§€ì…˜ ì ìš©
        """
        if len(segments) == 1:
            shutil.copy(segments[0]['path'], output_path)
            return
        
        import tempfile
        
        # ê·¸ë£¹ ë¶„í• : íŠ¸ëœì§€ì…˜ì´ í•„ìš”í•œ ì§€ì ì—ì„œ ë¶„í• 
        groups = []
        current_group = [segments[0]]
        
        for i in range(1, len(segments)):
            if segments[i]['needs_transition']:
                # íŠ¸ëœì§€ì…˜ í•„ìš” = ìƒˆ ê·¸ë£¹ ì‹œì‘
                groups.append(current_group)
                current_group = [segments[i]]
            else:
                # ì—°ì† ì”¬ = í˜„ì¬ ê·¸ë£¹ì— ì¶”ê°€
                current_group.append(segments[i])
        
        groups.append(current_group)  # ë§ˆì§€ë§‰ ê·¸ë£¹ ì¶”ê°€
        
        logger.info(f"ğŸ“¦ Split into {len(groups)} groups for processing")
        
        # 1ë‹¨ê³„: ê° ê·¸ë£¹ì„ í•˜ë‚˜ì˜ ë¹„ë””ì˜¤ë¡œ concat
        temp_dir = Path(tempfile.mkdtemp())
        group_videos = []
        
        try:
            for idx, group in enumerate(groups):
                if len(group) == 1:
                    # ë‹¨ì¼ ë¹„ë””ì˜¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    group_videos.append(group[0]['path'])
                    logger.debug(f"   Group {idx+1}: 1 video (pass-through)")
                else:
                    # ì—¬ëŸ¬ ë¹„ë””ì˜¤ë©´ concat
                    group_output = temp_dir / f"group_{idx}.mp4"
                    self._simple_concat(group, group_output)
                    group_videos.append(group_output)
                    logger.debug(f"   Group {idx+1}: {len(group)} videos -> {group_output.name}")
            
            # 2ë‹¨ê³„: ê·¸ë£¹ ê°„ íŠ¸ëœì§€ì…˜ ì ìš©
            if len(group_videos) == 1:
                shutil.copy(group_videos[0], output_path)
            elif self.transition_type == "fade_to_black":
                # Fade to Black: ê¸¸ì´ê°€ ì¤„ì§€ ì•ŠìŒ
                self._fade_to_black_groups(group_videos, output_path)
            else:
                # xfade: ì¤‘ì²©ë˜ì–´ ê¸¸ì´ê°€ ì¤„ì–´ë“¦
                self._xfade_groups(group_videos, output_path)
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            shutil.rmtree(temp_dir, ignore_errors=True)
    
    def _simple_concat(self, segments: list, output_path: Path) -> None:
        """ë‹¨ìˆœ concat (ì—°ì† ì”¬ìš©)."""
        # concat demuxer ë°©ì‹ ì‚¬ìš©
        list_file = output_path.parent / f"{output_path.stem}_list.txt"
        
        try:
            with open(list_file, 'w', encoding='utf-8') as f:
                for seg in segments:
                    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ê³  ë°±ìŠ¬ë˜ì‹œë¥¼ ìŠ¬ë˜ì‹œë¡œ ë³€ê²½
                    abs_path = Path(seg['path']).resolve()
                    path_str = str(abs_path).replace('\\', '/')
                    f.write(f"file '{path_str}'\n")
            
            cmd = [
                "ffmpeg", "-y", "-f", "concat", "-safe", "0",
                "-i", str(list_file),
                "-c", "copy",
                str(output_path)
            ]
            result = subprocess.run(cmd, capture_output=True)
            if result.returncode != 0:
                logger.error(f"Concat error: {result.stderr.decode()}")
                # í´ë°±: ì¬ì¸ì½”ë”© ë°©ì‹
                self._concat_with_reencode(segments, output_path)
        finally:
            if list_file.exists():
                list_file.unlink()
    
    def _concat_with_reencode(self, segments: list, output_path: Path) -> None:
        """ì¬ì¸ì½”ë”© ë°©ì‹ concat (í´ë°±ìš©)."""
        inputs = []
        for seg in segments:
            inputs.extend(["-i", str(seg['path'])])
        
        filter_str = "".join([f"[{i}:v]" for i in range(len(segments))]) + f"concat=n={len(segments)}:v=1:a=0[outv]"
        
        cmd = ["ffmpeg", "-y"]
        cmd.extend(inputs)
        cmd.extend([
            "-filter_complex", filter_str,
            "-map", "[outv]",
            "-c:v", "libx264",
            "-preset", "fast",
            "-crf", "18",
            str(output_path)
        ])
        subprocess.run(cmd, capture_output=True, check=True)
    
    def _fade_to_black_groups(self, group_videos: list, output_path: Path) -> None:
        """
        Fade to Black ë°©ì‹ íŠ¸ëœì§€ì…˜.
        
        ê° ê·¸ë£¹ì˜ ëì— fadeout, ì‹œì‘ì— fadein ì ìš©.
        ì¤‘ì²© ì—†ì´ concatí•˜ë¯€ë¡œ ê¸¸ì´ê°€ ì¤„ì§€ ì•ŠìŒ.
        """
        import tempfile
        temp_dir = Path(tempfile.mkdtemp())
        
        try:
            processed_videos = []
            fade_duration = self.transition_duration
            
            for i, video in enumerate(group_videos):
                # ë¹„ë””ì˜¤ ê¸¸ì´ ì¸¡ì •
                probe_cmd = [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "csv=p=0",
                    str(video)
                ]
                result = subprocess.run(probe_cmd, capture_output=True, text=True)
                try:
                    duration = float(result.stdout.strip())
                except:
                    duration = 5.0
                
                output_temp = temp_dir / f"faded_{i}.mp4"
                
                # ì²« ë²ˆì§¸ê°€ ì•„ë‹ˆë©´ fadein, ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ fadeout
                filters = []
                
                if i > 0:
                    # Fade in from black
                    filters.append(f"fade=t=in:st=0:d={fade_duration}")
                
                if i < len(group_videos) - 1:
                    # Fade out to black
                    fadeout_start = max(0, duration - fade_duration)
                    filters.append(f"fade=t=out:st={fadeout_start:.2f}:d={fade_duration}")
                
                if filters:
                    filter_str = ",".join(filters)
                    cmd = [
                        "ffmpeg", "-y",
                        "-i", str(video),
                        "-vf", filter_str,
                        "-c:v", "libx264",
                        "-preset", "fast",
                        "-crf", "18",
                        str(output_temp)
                    ]
                    subprocess.run(cmd, capture_output=True, check=True)
                    processed_videos.append(output_temp)
                else:
                    # í•„í„° ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    processed_videos.append(video)
            
            # Concat demuxerë¡œ ì—°ê²°
            list_file = temp_dir / "fade_list.txt"
            with open(list_file, 'w', encoding='utf-8') as f:
                for v in processed_videos:
                    path_str = str(Path(v).resolve()).replace('\\', '/')
                    f.write(f"file '{path_str}'\n")
            
            cmd = [
                "ffmpeg", "-y", "-f", "concat", "-safe", "0",
                "-i", str(list_file),
                "-c", "copy",
                str(output_path)
            ]
            result = subprocess.run(cmd, capture_output=True)
            
            if result.returncode != 0:
                logger.error(f"Fade concat error: {result.stderr.decode()}")
                # í´ë°±: ì¬ì¸ì½”ë”© ë°©ì‹
                inputs = []
                for v in processed_videos:
                    inputs.extend(["-i", str(v)])
                
                filter_str = "".join([f"[{i}:v]" for i in range(len(processed_videos))]) + f"concat=n={len(processed_videos)}:v=1:a=0[outv]"
                
                cmd2 = ["ffmpeg", "-y"]
                cmd2.extend(inputs)
                cmd2.extend([
                    "-filter_complex", filter_str,
                    "-map", "[outv]",
                    "-c:v", "libx264",
                    "-preset", "fast",
                    "-crf", "18",
                    str(output_path)
                ])
                subprocess.run(cmd2, capture_output=True, check=True)
            
            logger.info(f"âœ… Fade to Black transition applied ({len(group_videos)} groups)")
        
        finally:
            shutil.rmtree(temp_dir, ignore_errors=True)
    
    def _xfade_groups(self, group_videos: list, output_path: Path) -> None:
        """ê·¸ë£¹ ê°„ xfade ì ìš©."""
        
        def get_video_duration(path):
            try:
                probe_cmd = [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "csv=p=0",
                    str(path)
                ]
                result = subprocess.run(probe_cmd, capture_output=True, text=True)
                return float(result.stdout.strip())
            except:
                return 5.0
        
        inputs = []
        filter_parts = []
        
        for i, video in enumerate(group_videos):
            inputs.extend(["-i", str(video)])
        
        # ëª¨ë“  ì…ë ¥ ì •ê·œí™”
        normalized = []
        for i in range(len(group_videos)):
            filter_parts.append(f"[{i}:v]fps=16,settb=AVTB[n{i}]")
            normalized.append(f"[n{i}]")
        
        # ìˆœì°¨ì  xfade
        current_label = normalized[0]
        accumulated_duration = get_video_duration(group_videos[0])
        
        for i in range(1, len(group_videos)):
            next_input = normalized[i]
            out_label = f"[v{i}]"
            video_duration = get_video_duration(group_videos[i])
            
            offset = max(0, accumulated_duration - self.transition_duration)
            
            filter_parts.append(
                f"{current_label}{next_input}xfade=transition=fade:duration={self.transition_duration}:offset={offset:.2f}{out_label}"
            )
            
            accumulated_duration = offset + video_duration
            current_label = out_label
        
        filter_complex = ";".join(filter_parts)
        
        cmd = ["ffmpeg", "-y"]
        cmd.extend(inputs)
        cmd.extend([
            "-filter_complex", filter_complex,
            "-map", current_label,
            "-c:v", "libx264",
            "-preset", "medium",
            "-crf", "18",
            str(output_path)
        ])
        
        result = subprocess.run(cmd, capture_output=True)
        if result.returncode != 0:
            logger.error(f"FFmpeg xfade error: {result.stderr.decode()}")
            # í´ë°±: ë‹¨ìˆœ concat
            logger.info("Falling back to simple concatenation...")
            concat = VideoConcatenator(output_dir=str(output_path.parent))
            concat.concatenate([Path(v) for v in group_videos], output_path.name, reencode=True)


def smart_concat(
    csv_path: str,
    video_dir: str,
    output_filename: str = "final_smart.mp4",
    transition_duration: float = 0.3,
    transition_type: str = "crossfade"
) -> str:
    """
    ìŠ¤ë§ˆíŠ¸ íŠ¸ëœì§€ì…˜ ì—°ê²° ê°„í¸ í•¨ìˆ˜.
    
    CSVë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆ ì”¬ì—ë§Œ íŠ¸ëœì§€ì…˜ì„ ì ìš©í•©ë‹ˆë‹¤.
    
    Args:
        csv_path: Production Table CSV ê²½ë¡œ
        video_dir: ë¹„ë””ì˜¤ íŒŒì¼ ë””ë ‰í† ë¦¬
        output_filename: ì¶œë ¥ íŒŒì¼ëª…
        transition_duration: íŠ¸ëœì§€ì…˜ ê¸¸ì´ (ì´ˆ)
        transition_type: "crossfade" (ì¤‘ì²©, ê¸¸ì´ ì¤„ì–´ë“¦) ë˜ëŠ” "fade_to_black" (ê¸¸ì´ ìœ ì§€)
        
    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Example:
        >>> smart_concat(
        ...     csv_path="assets/production_table.csv",
        ...     video_dir="assets/images",
        ...     output_filename="final_music_video.mp4",
        ...     transition_type="fade_to_black"  # ê¸¸ì´ ìœ ì§€
        ... )
    """
    smart = SmartConcatenator(
        csv_path=csv_path,
        video_dir=video_dir,
        transition_duration=transition_duration,
        transition_type=transition_type
    )
    return smart.concatenate_smart(output_filename)

