"""
Video Upscaler - Real-ESRGAN based video upscaling module

720p â†’ 1440p ë¹„ë””ì˜¤ ì—…ìŠ¤ì¼€ì¼ì„ ìœ„í•œ ëª¨ë“ˆì…ë‹ˆë‹¤.
Real-ESRGANì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ë³„ë¡œ ì—…ìŠ¤ì¼€ì¼ í›„ ì¬ì¡°í•©í•©ë‹ˆë‹¤.
"""

import os
import subprocess
import shutil
import tempfile
from pathlib import Path
from typing import Optional, Callable
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class VideoUpscaler:
    """
    Real-ESRGAN ê¸°ë°˜ ë¹„ë””ì˜¤ ì—…ìŠ¤ì¼€ì¼ëŸ¬.
    
    720p (1280x720) â†’ 1440p (2560x1440) ì—…ìŠ¤ì¼€ì¼ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        model_name: str = "realesr-animevideov3",
        scale: int = 2,
        gpu_id: int = 0
    ):
        """
        Args:
            model_name: Real-ESRGAN ëª¨ë¸ëª…
                - "realesr-animevideov3" (ì• ë‹ˆë©”ì´ì…˜/AI ìƒì„± ì˜ìƒì— ìµœì )
                - "RealESRGAN_x4plus" (ì‹¤ì‚¬ ì˜ìƒ)
                - "RealESRGAN_x4plus_anime_6B" (ì• ë‹ˆë©”ì´ì…˜)
            scale: ì—…ìŠ¤ì¼€ì¼ ë°°ìœ¨ (2 = 720pâ†’1440p, 4 = 720pâ†’4K)
            gpu_id: ì‚¬ìš©í•  GPU ID
        """
        self.model_name = model_name
        self.scale = scale
        self.gpu_id = gpu_id
        self._check_dependencies()
    
    def _check_dependencies(self) -> None:
        """í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸."""
        # Check for realesrgan-ncnn-vulkan or Python realesrgan
        self.use_ncnn = shutil.which("realesrgan-ncnn-vulkan") is not None
        
        if not self.use_ncnn:
            try:
                from realesrgan import RealESRGANer
                self.use_python = True
            except ImportError:
                self.use_python = False
                logger.warning(
                    "Real-ESRGAN not found. Install via:\n"
                    "  pip install realesrgan basicsr\n"
                    "Or download realesrgan-ncnn-vulkan from:\n"
                    "  https://github.com/xinntao/Real-ESRGAN-ncnn-vulkan/releases"
                )
        else:
            self.use_python = False
    
    def upscale_video(
        self,
        input_path: str,
        output_path: Optional[str] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> str:
        """
        ë¹„ë””ì˜¤ë¥¼ ì—…ìŠ¤ì¼€ì¼í•©ë‹ˆë‹¤.
        
        Args:
            input_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
            progress_callback: ì§„í–‰ë¥  ì½œë°± (current_frame, total_frames)
            
        Returns:
            ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        """
        input_path = Path(input_path)
        if not input_path.exists():
            raise FileNotFoundError(f"Input video not found: {input_path}")
        
        if output_path is None:
            stem = input_path.stem
            suffix = input_path.suffix
            output_path = input_path.parent / f"{stem}_1440p{suffix}"
        else:
            output_path = Path(output_path)
        
        logger.info(f"ğŸ¬ Upscaling video: {input_path}")
        logger.info(f"   Output: {output_path}")
        logger.info(f"   Scale: {self.scale}x, Model: {self.model_name}")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            frames_dir = Path(temp_dir) / "frames"
            upscaled_dir = Path(temp_dir) / "upscaled"
            frames_dir.mkdir()
            upscaled_dir.mkdir()
            
            # Step 1: Extract frames
            logger.info("ğŸ“¤ Extracting frames...")
            fps = self._extract_frames(input_path, frames_dir)
            
            # Step 2: Upscale frames
            logger.info("ğŸ”„ Upscaling frames...")
            frame_count = len(list(frames_dir.glob("*.png")))
            self._upscale_frames(frames_dir, upscaled_dir, progress_callback, frame_count)
            
            # Step 3: Reassemble video
            logger.info("ğŸ“¥ Reassembling video...")
            self._reassemble_video(upscaled_dir, output_path, fps, input_path)
        
        logger.info(f"âœ… Upscaling complete: {output_path}")
        return str(output_path)
    
    def _extract_frames(self, video_path: Path, output_dir: Path) -> float:
        """FFmpegë¡œ í”„ë ˆì„ ì¶”ì¶œ."""
        # Get video FPS
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-select_streams", "v:0",
            "-show_entries", "stream=r_frame_rate",
            "-of", "csv=p=0",
            str(video_path)
        ]
        result = subprocess.run(probe_cmd, capture_output=True, text=True)
        fps_str = result.stdout.strip()
        if "/" in fps_str:
            num, den = map(int, fps_str.split("/"))
            fps = num / den
        else:
            fps = float(fps_str) if fps_str else 30.0
        
        # Extract frames
        extract_cmd = [
            "ffmpeg", "-i", str(video_path),
            "-qscale:v", "2",
            str(output_dir / "frame_%06d.png")
        ]
        subprocess.run(extract_cmd, capture_output=True, check=True)
        
        return fps
    
    def _upscale_frames(
        self,
        input_dir: Path,
        output_dir: Path,
        progress_callback: Optional[Callable],
        total_frames: int
    ) -> None:
        """í”„ë ˆì„ ì—…ìŠ¤ì¼€ì¼."""
        if self.use_ncnn:
            # Use realesrgan-ncnn-vulkan
            cmd = [
                "realesrgan-ncnn-vulkan",
                "-i", str(input_dir),
                "-o", str(output_dir),
                "-n", self.model_name,
                "-s", str(self.scale),
                "-g", str(self.gpu_id),
                "-f", "png"
            ]
            subprocess.run(cmd, check=True)
        elif self.use_python:
            self._upscale_frames_python(input_dir, output_dir, progress_callback, total_frames)
        else:
            raise RuntimeError("No Real-ESRGAN backend available")
    
    def _upscale_frames_python(
        self,
        input_dir: Path,
        output_dir: Path,
        progress_callback: Optional[Callable],
        total_frames: int
    ) -> None:
        """Python Real-ESRGANìœ¼ë¡œ í”„ë ˆì„ ì—…ìŠ¤ì¼€ì¼."""
        import cv2
        import torch
        from basicsr.archs.rrdbnet_arch import RRDBNet
        from realesrgan import RealESRGANer
        
        # Initialize model
        if self.model_name == "realesr-animevideov3":
            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=6, num_grow_ch=32, scale=4)
            netscale = 4
        else:
            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)
            netscale = 4
        
        upsampler = RealESRGANer(
            scale=netscale,
            model_path=None,  # Will auto-download
            model=model,
            half=True,
            gpu_id=self.gpu_id
        )
        
        frames = sorted(input_dir.glob("*.png"))
        for i, frame_path in enumerate(frames):
            img = cv2.imread(str(frame_path), cv2.IMREAD_UNCHANGED)
            output, _ = upsampler.enhance(img, outscale=self.scale)
            
            output_path = output_dir / frame_path.name
            cv2.imwrite(str(output_path), output)
            
            if progress_callback:
                progress_callback(i + 1, total_frames)
    
    def _reassemble_video(
        self,
        frames_dir: Path,
        output_path: Path,
        fps: float,
        original_video: Path
    ) -> None:
        """FFmpegë¡œ ë¹„ë””ì˜¤ ì¬ì¡°í•©."""
        # Check if original has audio
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-select_streams", "a:0",
            "-show_entries", "stream=codec_type",
            "-of", "csv=p=0",
            str(original_video)
        ]
        result = subprocess.run(probe_cmd, capture_output=True, text=True)
        has_audio = "audio" in result.stdout
        
        if has_audio:
            # With audio
            cmd = [
                "ffmpeg", "-y",
                "-framerate", str(fps),
                "-i", str(frames_dir / "frame_%06d.png"),
                "-i", str(original_video),
                "-map", "0:v", "-map", "1:a?",
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                "-pix_fmt", "yuv420p",
                "-c:a", "aac",
                str(output_path)
            ]
        else:
            # No audio
            cmd = [
                "ffmpeg", "-y",
                "-framerate", str(fps),
                "-i", str(frames_dir / "frame_%06d.png"),
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                "-pix_fmt", "yuv420p",
                str(output_path)
            ]
        
        subprocess.run(cmd, capture_output=True, check=True)


def upscale_video(
    input_path: str,
    output_path: Optional[str] = None,
    scale: int = 2,
    model: str = "realesr-animevideov3"
) -> str:
    """
    ë¹„ë””ì˜¤ ì—…ìŠ¤ì¼€ì¼ ê°„í¸ í•¨ìˆ˜.
    
    Args:
        input_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        scale: ì—…ìŠ¤ì¼€ì¼ ë°°ìœ¨ (2 = 720pâ†’1440p)
        model: Real-ESRGAN ëª¨ë¸ëª…
        
    Returns:
        ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
    """
    upscaler = VideoUpscaler(model_name=model, scale=scale)
    return upscaler.upscale_video(input_path, output_path)


# CLI support
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python upscale.py <input_video> [output_video]")
        print("       Upscales 720p video to 1440p using Real-ESRGAN")
        sys.exit(1)
    
    input_video = sys.argv[1]
    output_video = sys.argv[2] if len(sys.argv) > 2 else None
    
    try:
        result = upscale_video(input_video, output_video)
        print(f"âœ… Output saved to: {result}")
    except Exception as e:
        print(f"âŒ Error: {e}")
        sys.exit(1)


# ============================================================
# VIDEO CONCATENATION
# ============================================================

class VideoConcatenator:
    """
    ì—¬ëŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ì„ í•˜ë‚˜ë¡œ ì´ì–´ë¶™ì´ëŠ” í´ë˜ìŠ¤.
    
    FFmpegì˜ concat demuxerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬´ì†ì‹¤ ì—°ê²°í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, output_dir: Optional[str] = None):
        """
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ì²« ë²ˆì§¸ ì…ë ¥ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
        """
        self.output_dir = Path(output_dir) if output_dir else None
    
    def concatenate(
        self,
        video_paths: list,
        output_filename: str = "final_output.mp4",
        reencode: bool = False
    ) -> str:
        """
        ì—¬ëŸ¬ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
        
        Args:
            video_paths: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ìˆœì„œëŒ€ë¡œ ì—°ê²°)
            output_filename: ì¶œë ¥ íŒŒì¼ëª…
            reencode: Trueë©´ ì¬ì¸ì½”ë”© (ë‹¤ë¥¸ ì½”ë±/í•´ìƒë„ ë¹„ë””ì˜¤ ì—°ê²° ì‹œ)
            
        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        if len(video_paths) < 2:
            raise ValueError("At least 2 videos required for concatenation")
        
        # Validate all files exist
        video_paths = [Path(p) for p in video_paths]
        for vp in video_paths:
            if not vp.exists():
                raise FileNotFoundError(f"Video not found: {vp}")
        
        # Determine output directory
        if self.output_dir:
            output_dir = self.output_dir
        else:
            output_dir = video_paths[0].parent
        
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / output_filename
        
        logger.info(f"ğŸ¬ Concatenating {len(video_paths)} videos...")
        
        if reencode:
            self._concat_with_reencode(video_paths, output_path)
        else:
            self._concat_demuxer(video_paths, output_path)
        
        logger.info(f"âœ… Concatenation complete: {output_path}")
        return str(output_path)
    
    def _concat_demuxer(self, video_paths: list, output_path: Path) -> None:
        """FFmpeg concat demuxer ì‚¬ìš© (ë¬´ì†ì‹¤, ê°™ì€ ì½”ë± í•„ìš”)."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            for vp in video_paths:
                # Escape single quotes in path
                escaped_path = str(vp.absolute()).replace("'", "'\\''")
                f.write(f"file '{escaped_path}'\n")
            concat_list = f.name
        
        try:
            cmd = [
                "ffmpeg", "-y",
                "-f", "concat",
                "-safe", "0",
                "-i", concat_list,
                "-c", "copy",
                str(output_path)
            ]
            subprocess.run(cmd, capture_output=True, check=True)
        finally:
            os.unlink(concat_list)
    
    def _concat_with_reencode(self, video_paths: list, output_path: Path) -> None:
        """ì¬ì¸ì½”ë”©í•˜ë©´ì„œ ì—°ê²° (ë‹¤ë¥¸ ì½”ë±/í•´ìƒë„ ì§€ì›)."""
        # Check if videos have audio
        has_audio = self._check_video_has_audio(video_paths[0])
        
        # Build filter complex for concat
        filter_complex = ""
        for i in range(len(video_paths)):
            if has_audio:
                filter_complex += f"[{i}:v][{i}:a]"
            else:
                filter_complex += f"[{i}:v]"
        
        if has_audio:
            filter_complex += f"concat=n={len(video_paths)}:v=1:a=1[outv][outa]"
        else:
            filter_complex += f"concat=n={len(video_paths)}:v=1:a=0[outv]"
        
        cmd = [
            "ffmpeg", "-y",
        ]
        for vp in video_paths:
            cmd.extend(["-i", str(vp)])
        
        if has_audio:
            cmd.extend([
                "-filter_complex", filter_complex,
                "-map", "[outv]",
                "-map", "[outa]",
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                "-c:a", "aac",
                "-b:a", "192k",
                str(output_path)
            ])
        else:
            cmd.extend([
                "-filter_complex", filter_complex,
                "-map", "[outv]",
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                str(output_path)
            ])
        subprocess.run(cmd, capture_output=True, check=True)
    
    def _check_video_has_audio(self, video_path: Path) -> bool:
        """ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì´ ìˆëŠ”ì§€ í™•ì¸."""
        try:
            probe_cmd = [
                "ffprobe", "-v", "error",
                "-select_streams", "a:0",
                "-show_entries", "stream=codec_type",
                "-of", "csv=p=0",
                str(video_path)
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True)
            return "audio" in result.stdout
        except Exception:
            return False
    
    def concatenate_directory(
        self,
        directory: str,
        pattern: str = "*.mp4",
        output_filename: str = "final_output.mp4",
        sort_by: str = "name"
    ) -> str:
        """
        ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
        
        Args:
            directory: ë¹„ë””ì˜¤ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬
            pattern: íŒŒì¼ íŒ¨í„´ (ì˜ˆ: "*.mp4", "block_*.mp4")
            output_filename: ì¶œë ¥ íŒŒì¼ëª…
            sort_by: ì •ë ¬ ê¸°ì¤€ ("name" ë˜ëŠ” "time")
            
        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        dir_path = Path(directory)
        if not dir_path.exists():
            raise FileNotFoundError(f"Directory not found: {directory}")
        
        videos = list(dir_path.glob(pattern))
        if not videos:
            raise ValueError(f"No videos matching '{pattern}' in {directory}")
        
        # Sort videos
        if sort_by == "name":
            videos.sort(key=lambda x: x.name)
        elif sort_by == "time":
            videos.sort(key=lambda x: x.stat().st_mtime)
        else:
            raise ValueError(f"Invalid sort_by: {sort_by}")
        
        logger.info(f"ğŸ“‚ Found {len(videos)} videos in {directory}")
        for i, v in enumerate(videos):
            logger.info(f"   {i+1}. {v.name}")
        
        return self.concatenate(videos, output_filename)


def concat_videos(
    video_paths: list,
    output_path: Optional[str] = None,
    reencode: bool = False
) -> str:
    """
    ë¹„ë””ì˜¤ ì—°ê²° ê°„í¸ í•¨ìˆ˜.
    
    Args:
        video_paths: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        reencode: ì¬ì¸ì½”ë”© ì—¬ë¶€
        
    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    output_filename = Path(output_path).name if output_path else "final_output.mp4"
    output_dir = Path(output_path).parent if output_path else None
    
    concat = VideoConcatenator(output_dir=str(output_dir) if output_dir else None)
    return concat.concatenate(video_paths, output_filename, reencode)


def concat_directory(
    directory: str,
    pattern: str = "*.mp4",
    output_filename: str = "final_output.mp4"
) -> str:
    """
    ë””ë ‰í† ë¦¬ ë‚´ ë¹„ë””ì˜¤ ì—°ê²° ê°„í¸ í•¨ìˆ˜.
    
    Args:
        directory: ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬
        pattern: íŒŒì¼ íŒ¨í„´
        output_filename: ì¶œë ¥ íŒŒì¼ëª…
        
    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    concat = VideoConcatenator()
    return concat.concatenate_directory(directory, pattern, output_filename)


# ============================================================
# SMART CONCATENATOR - Scene-aware transitions
# ============================================================

class SmartConcatenator:
    """
    ìŠ¤ë§ˆíŠ¸ ë¹„ë””ì˜¤ ì—°ê²°ê¸° - CSV ë¶„ì„í•˜ì—¬ ìƒˆ ì”¬ì—ë§Œ íŠ¸ëœì§€ì…˜ ì ìš©.
    
    Production Table CSVë¥¼ ë¶„ì„í•˜ì—¬:
    - [Input: Last Frame]ë¡œ ì‹œì‘í•˜ëŠ” ë¸”ë¡: íŠ¸ëœì§€ì…˜ ì—†ì´ ì—°ê²° (ì—°ì† ì”¬)
    - ìƒˆ í”„ë¡¬í”„íŠ¸ë¡œ ì‹œì‘í•˜ëŠ” ë¸”ë¡: í¬ë¡œìŠ¤í˜ì´ë“œ íŠ¸ëœì§€ì…˜ ì ìš© (ìƒˆ ì”¬)
    """
    
    def __init__(
        self,
        csv_path: str,
        video_dir: str,
        transition_duration: float = 0.3,
        transition_type: str = "crossfade"
    ):
        """
        Args:
            csv_path: Production Table CSV ê²½ë¡œ
            video_dir: ë¹„ë””ì˜¤ íŒŒì¼ ë””ë ‰í† ë¦¬
            transition_duration: íŠ¸ëœì§€ì…˜ ê¸¸ì´ (ì´ˆ)
            transition_type: íŠ¸ëœì§€ì…˜ íƒ€ì… ("crossfade", "fade_black")
        """
        self.csv_path = Path(csv_path)
        self.video_dir = Path(video_dir)
        self.transition_duration = transition_duration
        self.transition_type = transition_type
        
        if not self.csv_path.exists():
            raise FileNotFoundError(f"CSV not found: {csv_path}")
        if not self.video_dir.exists():
            raise FileNotFoundError(f"Video directory not found: {video_dir}")
    
    def analyze_transitions(self) -> list:
        """
        CSVë¥¼ ë¶„ì„í•˜ì—¬ íŠ¸ëœì§€ì…˜ì´ í•„ìš”í•œ ë¸”ë¡ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Returns:
            list of tuples: [(block_id, needs_transition), ...]
        """
        import pandas as pd
        
        df = pd.read_csv(self.csv_path)
        transitions = []
        
        for index, row in df.iterrows():
            block_id = str(row['Block']).zfill(2)
            start_frame_prompt = str(row.get('Nano Banana (Start Frame)', ''))
            section = str(row.get('Section', ''))
            
            # ì´ì „ ë¸”ë¡ì˜ ì„¹ì…˜ (ìˆë‹¤ë©´)
            prev_section = df.iloc[index - 1]['Section'] if index > 0 else None
            
            # íŠ¸ëœì§€ì…˜ì´ í•„ìš”í•œ ì¡°ê±´:
            # 1. [Input: Last Frame]ë¡œ ì‹œì‘í•˜ì§€ ì•ŠìŒ (ìƒˆ ì”¬)
            # 2. ì„¹ì…˜ì´ ë³€ê²½ë¨ (Intro â†’ Verse ë“±)
            # 3. ì²« ë¸”ë¡ì´ ì•„ë‹˜
            is_continuation = "[Input: Last Frame" in start_frame_prompt or "[Loop Bank" in start_frame_prompt
            section_changed = prev_section is not None and section != prev_section
            
            needs_transition = False
            if index > 0:  # ì²« ë¸”ë¡ì€ íŠ¸ëœì§€ì…˜ ë¶ˆí•„ìš”
                if not is_continuation or section_changed:
                    needs_transition = True
            
            transitions.append({
                'block_id': block_id,
                'needs_transition': needs_transition,
                'section': section,
                'reason': 'new_scene' if not is_continuation else ('section_change' if section_changed else 'continuation')
            })
            
            logger.debug(f"Block {block_id}: transition={needs_transition}, reason={transitions[-1]['reason']}")
        
        return transitions
    
    def concatenate_smart(
        self,
        output_filename: str = "final_smart.mp4",
        video_pattern: str = "block_{block_id}_video.mp4"
    ) -> str:
        """
        ìŠ¤ë§ˆíŠ¸ íŠ¸ëœì§€ì…˜ìœ¼ë¡œ ë¹„ë””ì˜¤ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
        
        Args:
            output_filename: ì¶œë ¥ íŒŒì¼ëª…
            video_pattern: ë¹„ë””ì˜¤ íŒŒì¼ íŒ¨í„´ ({block_id}ëŠ” ìë™ ì¹˜í™˜)
            
        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        transitions = self.analyze_transitions()
        
        # ì¡´ì¬í•˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        video_segments = []
        for t in transitions:
            video_name = video_pattern.format(block_id=t['block_id'])
            video_path = self.video_dir / video_name
            if video_path.exists():
                video_segments.append({
                    'path': video_path,
                    'block_id': t['block_id'],
                    'needs_transition': t['needs_transition'],
                    'reason': t['reason']
                })
            else:
                logger.warning(f"Video not found: {video_path}")
        
        if not video_segments:
            raise ValueError("No video files found")
        
        logger.info(f"ğŸ¬ Smart concatenation: {len(video_segments)} videos")
        for seg in video_segments:
            trans_mark = "ğŸ”€" if seg['needs_transition'] else "â¡ï¸"
            logger.info(f"   {trans_mark} Block {seg['block_id']} ({seg['reason']})")
        
        # íŠ¸ëœì§€ì…˜ í•„ìš”í•œ ë¶€ë¶„ ì¹´ìš´íŠ¸
        trans_count = sum(1 for seg in video_segments if seg['needs_transition'])
        logger.info(f"ğŸ“Š {trans_count} transitions will be applied")
        
        # FFmpegë¡œ ìŠ¤ë§ˆíŠ¸ ì—°ê²°
        output_path = self.video_dir / output_filename
        self._concatenate_with_transitions(video_segments, output_path)
        
        logger.info(f"âœ… Smart output saved: {output_path}")
        return str(output_path)
    
    def _concatenate_with_transitions(self, segments: list, output_path: Path) -> None:
        """FFmpegë¡œ íŠ¸ëœì§€ì…˜ í¬í•¨ ì—°ê²° (timebase ì •ê·œí™”)."""
        if len(segments) == 1:
            # ë‹¨ì¼ ë¹„ë””ì˜¤ë©´ ê·¸ëƒ¥ ë³µì‚¬
            shutil.copy(segments[0]['path'], output_path)
            return
        
        # ë¹„ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸° (offset ê³„ì‚°ìš©)
        def get_video_duration(path):
            try:
                probe_cmd = [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "csv=p=0",
                    str(path)
                ]
                result = subprocess.run(probe_cmd, capture_output=True, text=True)
                return float(result.stdout.strip())
            except:
                return 5.0  # ê¸°ë³¸ 5ì´ˆ
        
        # ì…ë ¥ ë° í•„í„° ì¤€ë¹„
        inputs = []
        filter_parts = []
        
        for i, seg in enumerate(segments):
            inputs.extend(["-i", str(seg['path'])])
        
        # ëª¨ë“  ì…ë ¥ì„ ë™ì¼í•œ timebaseë¡œ ì •ê·œí™” (1/25 fps ê¸°ì¤€)
        normalized = []
        for i in range(len(segments)):
            filter_parts.append(f"[{i}:v]settb=AVTB,fps=16[n{i}]")
            normalized.append(f"[n{i}]")
        
        # ìˆœì°¨ì ìœ¼ë¡œ xfade ë˜ëŠ” concat ì ìš©
        current_label = normalized[0]
        accumulated_duration = get_video_duration(segments[0]['path'])
        
        for i in range(1, len(segments)):
            seg = segments[i]
            next_input = normalized[i]
            out_label = f"[v{i}]"
            video_duration = get_video_duration(seg['path'])
            
            if seg['needs_transition']:
                # xfade: offset = í˜„ì¬ê¹Œì§€ ëˆ„ì  ê¸¸ì´ - íŠ¸ëœì§€ì…˜ ê¸¸ì´
                offset = max(0, accumulated_duration - self.transition_duration)
                
                if self.transition_type == "crossfade":
                    filter_parts.append(
                        f"{current_label}{next_input}xfade=transition=fade:duration={self.transition_duration}:offset={offset:.2f}{out_label}"
                    )
                elif self.transition_type == "fade_black":
                    filter_parts.append(
                        f"{current_label}{next_input}xfade=transition=fadeblack:duration={self.transition_duration}:offset={offset:.2f}{out_label}"
                    )
                
                # ëˆ„ì  ì‹œê°„ ì—…ë°ì´íŠ¸ (xfadeëŠ” ê²¹ì¹˜ë¯€ë¡œ íŠ¸ëœì§€ì…˜ ê¸¸ì´ë§Œí¼ ë¹¼ê¸°)
                accumulated_duration = offset + video_duration
            else:
                # íŠ¸ëœì§€ì…˜ ì—†ì´ concat
                filter_parts.append(
                    f"{current_label}{next_input}concat=n=2:v=1:a=0{out_label}"
                )
                accumulated_duration += video_duration
            
            current_label = out_label
        
        # FFmpeg ëª…ë ¹ ì‹¤í–‰
        filter_complex = ";".join(filter_parts)
        
        cmd = ["ffmpeg", "-y"]
        cmd.extend(inputs)
        cmd.extend([
            "-filter_complex", filter_complex,
            "-map", current_label,
            "-c:v", "libx264",
            "-preset", "medium",
            "-crf", "18",
            str(output_path)
        ])
        
        try:
            subprocess.run(cmd, capture_output=True, check=True)
        except subprocess.CalledProcessError as e:
            logger.error(f"FFmpeg error: {e.stderr.decode() if e.stderr else str(e)}")
            # í´ë°±: ë‹¨ìˆœ concat
            logger.info("Falling back to simple concatenation...")
            concat = VideoConcatenator(output_dir=str(output_path.parent))
            concat.concatenate([seg['path'] for seg in segments], output_path.name, reencode=True)


def smart_concat(
    csv_path: str,
    video_dir: str,
    output_filename: str = "final_smart.mp4",
    transition_duration: float = 0.3
) -> str:
    """
    ìŠ¤ë§ˆíŠ¸ íŠ¸ëœì§€ì…˜ ì—°ê²° ê°„í¸ í•¨ìˆ˜.
    
    CSVë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆ ì”¬ì—ë§Œ í¬ë¡œìŠ¤í˜ì´ë“œë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    
    Args:
        csv_path: Production Table CSV ê²½ë¡œ
        video_dir: ë¹„ë””ì˜¤ íŒŒì¼ ë””ë ‰í† ë¦¬
        output_filename: ì¶œë ¥ íŒŒì¼ëª…
        transition_duration: íŠ¸ëœì§€ì…˜ ê¸¸ì´ (ì´ˆ)
        
    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Example:
        >>> smart_concat(
        ...     csv_path="assets/production_table.csv",
        ...     video_dir="assets/images",
        ...     output_filename="final_music_video.mp4"
        ... )
    """
    smart = SmartConcatenator(
        csv_path=csv_path,
        video_dir=video_dir,
        transition_duration=transition_duration
    )
    return smart.concatenate_smart(output_filename)
